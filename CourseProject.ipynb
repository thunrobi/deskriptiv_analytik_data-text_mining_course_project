{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Mining Project\n",
        "\n",
        "This project performs basic text mining on an online news article. It downloads the article text from a user-provided URL, processes it using simple natural language techniques, summarizes the content, extracts key points, and allows the user to ask questions about the article.\n",
        "\n",
        "---\n",
        "\n",
        "## Main Steps\n",
        "\n",
        "1. **Download article text**\n",
        "   The program uses the `trafilatura` library to fetch and extract readable text from a webpage.\n",
        "\n",
        "2. **Tokenize the text**\n",
        "   Using NLTK, the article is split into sentences and words for further processing.\n",
        "\n",
        "3. **Generate a summary**\n",
        "   The first few sentences of the article are returned as a basic extractive summary.\n",
        "\n",
        "4. **Identify key points**\n",
        "   The program selects the most informative sentences by scoring them based on the number of unique words they contain.\n",
        "\n",
        "5. **Answer user questions**\n",
        "   When the user enters a question, the program compares the question words with each sentence in the article and returns the sentences with the highest overlap.\n",
        "\n",
        "6. **Interactive mode**\n",
        "   The user can ask multiple questions until choosing to stop.\n",
        "\n",
        "\n",
        "### When trying it out run this in a seperate cell: `!pip install trafilatura nltk`"
      ],
      "metadata": {
        "id": "OhDmdsqlsPPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trafilatura nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VNmkVauUy6G",
        "outputId": "8ea007ec-537e-4e7f-aaff-e55a54dab0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trafilatura in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2026.1.4)\n",
            "Requirement already satisfied: charset_normalizer>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.4.4)\n",
            "Requirement already satisfied: courlan>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.3.2)\n",
            "Requirement already satisfied: htmldate>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.9.4)\n",
            "Requirement already satisfied: justext>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.0.2)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (6.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
            "Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
            "Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3RgKaqzgFC5",
        "outputId": "11555c8f-6735-4f89-afc1-df481f9c9587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text mining from articles\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import trafilatura\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# Get article\n",
        "def extract_article_text(url):\n",
        "    downloaded = trafilatura.fetch_url(url)\n",
        "    text = trafilatura.extract(downloaded)\n",
        "\n",
        "\n",
        "# Summary\n",
        "def summary(sentences, n=5):\n",
        "    return sentences[:n]\n",
        "\n",
        "# Keypoints\n",
        "def extract_keypoints(sentences, top_k=3):\n",
        "    scored = []\n",
        "\n",
        "    for s in sentences:\n",
        "        tokens = word_tokenize(s)\n",
        "        words = []\n",
        "        for w in tokens:\n",
        "            w = w.lower()\n",
        "            if w.isalpha():\n",
        "                words.append(w)\n",
        "\n",
        "        score = len(set(words))\n",
        "        scored.append((score, s))\n",
        "\n",
        "    # sort by score, best first\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    keypoints = []\n",
        "    for score, sent in scored[:top_k]:\n",
        "        keypoints.append(sent)\n",
        "\n",
        "    return keypoints\n",
        "\n",
        "# Question answering\n",
        "def answer_question(question, sentences):\n",
        "\n",
        "    q_tokens = word_tokenize(question)\n",
        "    q_words = []\n",
        "    for w in q_tokens:\n",
        "        w = w.lower()\n",
        "        if w.isalpha():\n",
        "            q_words.append(w)\n",
        "\n",
        "    scored_sentences = []\n",
        "\n",
        "    for s in sentences:\n",
        "        s_tokens = word_tokenize(s)\n",
        "        s_words = []\n",
        "        for w in s_tokens:\n",
        "            w = w.lower()\n",
        "            if w.isalpha():\n",
        "                s_words.append(w)\n",
        "        score = 0\n",
        "        for qw in q_words:\n",
        "            if qw in s_words:\n",
        "                score += 1\n",
        "\n",
        "        scored_sentences.append((score, s))\n",
        "    scored_sentences.sort(reverse=True, key=lambda item: item[0])\n",
        "\n",
        "    answers = []\n",
        "    for score, sent in scored_sentences:\n",
        "        if score > 0:\n",
        "            answers.append(sent)\n",
        "        if len(answers) == 1:\n",
        "            break\n",
        "\n",
        "    return answers\n",
        "\n",
        "def main():\n",
        "    print(\"Text mining from articles\\n\")\n",
        "\n",
        "    url = input(\"Enter the article URL: \")\n",
        "\n",
        "    article = extract_article_text(url)\n",
        "\n",
        "    if article == \"\":\n",
        "        print(\"Could not get article text. Try another URL.\")\n",
        "        return\n",
        "\n",
        "    # Sentence tokenization\n",
        "    print(\"\\nSentence Tokenization\")\n",
        "    sentences = sent_tokenize(article)\n",
        "    for s in sentences[:10]:  # show first 10 sentences\n",
        "        print(\"-\", s)\n",
        "\n",
        "    # Word tokenization\n",
        "    print(\"\\nWord Tokenization\")\n",
        "    words = word_tokenize(article)\n",
        "    print(words[:30])  # show first 30 words\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\nSummary\")\n",
        "    summary_text = summary(sentences, n=5)\n",
        "    for s in summary_text:\n",
        "        print(\"-\", s)\n",
        "\n",
        "    # Key points\n",
        "    print(\"\\nKey points\")\n",
        "    keypoints = extract_keypoints(sentences, top_k=3)\n",
        "    for kp in keypoints:\n",
        "        print(\"-\", kp)\n",
        "\n",
        "    # Question loop\n",
        "    print(\"\\nAsk questions about the article.\")\n",
        "    print(\"Press Enter on an empty line to stop.\\n\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"Your question: \").strip()\n",
        "        if question == \"\":\n",
        "            break\n",
        "\n",
        "        answers = answer_question(question, sentences)\n",
        "\n",
        "        if answers:\n",
        "            print(\"\\nPossible answer:\")\n",
        "            for a in answers:\n",
        "                print(\"-\", a)\n",
        "        else:\n",
        "            print(\"No relevant answer found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYRTpe_xhqKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}